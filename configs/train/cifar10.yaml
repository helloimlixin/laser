# Main configuration file for CIFAR10 training
defaults:
  - data: cifar10
  - model: cifar10
  - _self_

seed: 42
output_dir: "./outputs/cifar10"

# Training configuration
training:
  learning_rate: 3.0e-4
  beta: 0.9
  max_epochs: 100
  accelerator: "gpu"
  devices: 1
  precision: 32
  gradient_clip_val: 1.0
  log_every_n_steps: 50
  early_stopping_patience: 10

# WandB configuration
wandb:
  project: "vae-bottlenecks"
  name: "cifar10"
  save_dir: "${output_dir}/wandb"

# Checkpoint configuration
checkpoint:
  dirpath: "${output_dir}/checkpoints"
  filename: "{model.type}-{epoch}-{val_loss:.2f}"
  save_top_k: 3
