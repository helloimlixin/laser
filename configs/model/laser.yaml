# Model type: laser (K-SVD Dictionary Learning VAE)
# Other options: vqvae
type: laser

# Number of input image channels
# Options: 3 (RGB), 1 (grayscale)
in_channels: 3

# Number of hidden units in encoder/decoder
# Typical range: 32-256
# Higher = more capacity, slower training
num_hiddens: 128

# Dictionary size (number of atoms/embeddings)
# Typical range: 128-1024
# Higher = more expressive, slower sparse coding
num_embeddings: 512

# Channel dimension of encoder output (NOT the full atom dimension!)
# Should match encoder output channels
# Typical range: 32-128
# NOTE: The actual dictionary atom dimension = embedding_dim × patch_size²
#       With embedding_dim=64 and patch_size=4: atom_dim = 64 × 16 = 1024
embedding_dim: 64

# Spatial patch size for patch-based dictionary learning
# Options: 1 (pixel-level), 2, 4, 8, 16, or tuple (h, w)
# 1 = pixel-level (atom_dim = embedding_dim), best quality, slowest
# 4 = patch-level (atom_dim = embedding_dim × 16), good balance
# 8 = patch-level (atom_dim = embedding_dim × 64), faster, lower quality
# 16+ = large patches, fastest, lower quality
# IMPORTANT: Larger patches = longer dictionary atoms = more parameters
patch_size: 4

# Sparsity level (max number of non-zero coefficients per signal/patch)
# Must be < num_embeddings
# Typical range: 4-32
# Lower = more sparse (better generalization, lower quality)
# Higher = less sparse (better quality, risk of overfitting)
# With patch_size > 1: each patch gets its own sparse representation
sparsity_level: 8

# Number of residual blocks in encoder/decoder
# Typical range: 2-6
# Higher = more capacity, deeper network
num_residual_blocks: 2

# Number of hidden units in residual blocks
# Typical range: 16-128
num_residual_hiddens: 32

# Commitment cost (weight for encoder loss term)
# Typical range: 0.1-1.0
# Higher = encoder forced to match dictionary reconstruction more closely
commitment_cost: 0.1

# Number of K-SVD dictionary update iterations per forward pass
# Options: 0 (disabled), 1-5
# 0 = gradient-based learning only
# 1-2 = fast K-SVD updates
# 3-5 = better atoms, slower
ksvd_iterations: 1

# Dictionary update frequency (update every N training steps)
# Options: 0 (every step), 1+ (every N steps)
# 0 = update every step (slowest, most stable)
# 10-20 = good balance between speed and stability
# Large values (100+) cause sudden dictionary changes → loss spikes
dictionary_update_frequency: 100

# Use online dictionary learning instead of K-SVD
# Options: true (fast online updates), false (classical K-SVD)
# true = faster, good for large datasets
# false = higher quality atoms, better for small datasets
use_online_learning: true

# Learning rate for online dictionary updates
# Only used if use_online_learning=true
# Typical range: 0.01-0.1 (CRITICAL: much lower for patch_size=1!)
# Higher = faster dictionary adaptation
# 0.3 was causing training instability - reduced to 0.05 for stability
dict_learning_rate: 0.05

# Sparse coding algorithm
# Options: 'omp' (best quality), 'iht' (recommended), 'topk' (fastest, not recommended)
# omp = Orthogonal Matching Pursuit (slow, best quality)
# iht = Iterative Hard Thresholding (fast, good quality, RECOMMENDED)
# topk = Top-K selection (fastest, poor quality, overfitting risk)
sparse_solver: omp

# Number of IHT iterations
# Only used if sparse_solver='iht'
# Typical range: 5-20
# 5-7 = fast, slight quality loss
# 10 = good balance (recommended)
# 15-20 = best quality, slower
iht_iterations: 10

# IHT step size (1/Lipschitz constant)
# Only used if sparse_solver='iht'
# Options: null (auto-compute, recommended), 0.5-1.0 (manual)
# null = automatically computed from spectral norm
# 0.9 = good manual default for normalized dictionaries
iht_step_size: null

# Use backprop-only mode (dictionary learned via gradients instead of K-SVD)
# Options: true (gradient-based), false (K-SVD/online learning)
# true = dictionary learned via gradients (smoother updates, may help overfitting)
# false = dictionary updated via K-SVD/online learning
# NOTE: When true, sparse coding still used! Only dictionary update changes.
use_backprop_only: false

# L1 regularization weight on sparse coefficients
# Typical range: 0.0-0.1
# 0.0 = no regularization
# 0.01 = mild regularization (recommended)
# 0.05-0.1 = strong regularization (max sparsity)
# Increase this if still overfitting with backprop-only mode
sparsity_reg_weight: 0.02  # Increased from 0.01 for stronger regularization

# Perceptual loss weight (LPIPS)
# Typical range: 0.0-2.0
# 0.0 = no perceptual loss
# 0.5-1.0 = good balance (recommended)
# Higher = better perceptual quality, slower training
# TEMPORARILY DISABLED: VGG16 causes OOM with DDP
perceptual_weight: 0.5

# Learning rate for encoder/decoder/dictionary (if use_backprop_only=true)
# Typical range: 1e-4 to 1e-3
# 1e-4 = stable, slower
# 1e-3 = faster, may be unstable
learning_rate: 1e-3

# Beta1 parameter for Adam/AdamW optimizer
# Typical range: 0.5-0.99
# 0.9 = standard default
beta: 0.9

# Compute FID (Frechet Inception Distance) during testing
# Options: true (slower, comprehensive), false (faster)
compute_fid: false

# Log reconstruction images to W&B every N steps
# Typical range: 100-1000
# Lower = more frequent logging, larger logs
log_images_every_n_steps: 500

# Multi-resolution DCT loss weight
# Typical range: 0.0-1.0
# 0.0 = disabled
# 0.5 = recommended for high-frequency detail preservation
multi_res_dct_weight: 0.5

# Number of pyramid levels for multi-resolution DCT loss
# Typical range: 2-4
multi_res_dct_levels: 3

# Multi-resolution gradient loss weight
# Typical range: 0.0-1.0
# 0.0 = disabled
# 0.5 = recommended for edge preservation
multi_res_grad_weight: 0.5

# Number of pyramid levels for multi-resolution gradient loss
# Typical range: 2-4
multi_res_grad_levels: 3

